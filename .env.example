# OpenStack Assistant Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Provider Configuration (Choose ONE)
# =============================================================================

# Option 1: Google Gemini
# Get an API key at: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# Optional: Gemini model to use
# Options: gemini-2.5-flash, gemini-2.5-pro, gemini-2.0-flash, gemini-2.0-flash-lite
# Default: gemini-2.5-flash
GEMINI_MODEL=gemini-2.5-flash

# Option 2: Granite
# Requires both URL and User Key
# URL can be either:
#   - Full URL with model routing: https://granite-4-0-h-tiny--apicast-production.apps.example.com:443/v1/chat/completions
#   - Base URL: https://apicast-production.apps.example.com (will auto-append /v1/chat/completions)
# GRANITE_URL=https://your-granite-api-endpoint.com
# GRANITE_USER_KEY=your-granite-user-key-here

# Optional: Granite configuration
# GRANITE_TEMPERATURE=0.0
# GRANITE_MAX_TOKENS=4096

# Optional: MCP server URL (if using a remote MCP server)
# MCP_SERVER_URL=http://localhost:3000

# Optional: MCP server command (if using a local MCP server)
# This will be executed to start the server
# Example: npx @modelcontextprotocol/server-filesystem /tmp
# MCP_SERVER_COMMAND=npx @modelcontextprotocol/server-filesystem /etc/openstack

# Optional: Default workflow file to use
# WORKFLOW_FILE=/path/to/workflow.json

# Optional: System instruction file for chat mode
# This defines the agent's identity and behavior in interactive chat
# Example: examples/rhoso-upgrade-agent.txt
# SYSTEM_INSTRUCTION_FILE=/path/to/system-instruction.txt
